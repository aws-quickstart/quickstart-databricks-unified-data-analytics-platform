AWSTemplateFormatVersion: 2010-09-09
Description: >-
  This template creates Databricks workspace resources in your AWS account using the API account. The API account is required if you want to use either customer managed VPCs or customer managed keys for notebooks. For feature availability, contact your Databricks representative. (qs-1r0odiedc)
Metadata:
  cfn-lint:
    config:
      ignore_checks:
        - W3005
        - W8001
        - W9006 # temporary to get rid of warnings
        - W9001
  QuickStartDocumentation:
    EntrypointName: "Parameters for deploying a workspace and creating a cross-account IAM role"
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "Workspace configuration"
        Parameters:
          - AccountId
          - Username
          - Password
          - PricingTier
          - DeploymentName
          - AWSRegion
          - HIPAAparm
      - Label:
          default: "IAM role and S3 bucket configuration"
        Parameters:
          - TagValue
          - IAMRole
          - BucketName
      - Label:
          default: "(Optional) Customer managed VPC configuration (requires the premium tier)"
        Parameters:
          - VPCID
          - SubnetIDs
          - SecurityGroupIDs
      - Label:
          default: "(Optional) Customer managed key configuration for notebooks (requires the enterprise tier)"
        Parameters:
          - KeyArn
          - KeyAlias
          - KeyUseCases
          - KeyReuseForClusterVolumes
      - Label:
          default: "Quick Start configuration"
        Parameters:
          - QSS3BucketName
          - QSS3KeyPrefix
    ParameterLabels:
      AccountId:
        default: Databricks account ID
      Username:
        default: Workspace account email
      Password:
        default: Workspace account password
      PricingTier:
        default: Pricing tier of the workspace
      DeploymentName:
        default: Workspace deployment name
      AWSRegion:
        default: AWS Region of the Databricks workspace 
      HIPAAparm:
        default: HIPAA tier account
      TagValue:
        default: IAM role tag
      IAMRole:
        default: Cross-account IAM role name
      BucketName:
        default: Root S3 bucket name 
      VPCID:
        default: VPC ID
      SubnetIDs:
        default: Private subnet IDs
      SecurityGroupIDs:
        default: Security group IDs
      KeyArn:
        default: ARN for the customer managed AWS KMS key
      KeyAlias:
        default: Alias for the customer managed AWS KMS key
      KeyUseCases:
        default: Use case for which to use the key
      KeyReuseForClusterVolumes:
        default: Encrypt cluster EBS volumes
      QSS3BucketName:
        default: Quick Start S3 bucket name
      QSS3KeyPrefix:
        default: Quick Start S3 key prefix

Outputs:
  CustomerManagedVPCIAMRoleARN:
    Description: ARN of the customer managed cross-account IAM role.
    Condition: CustomerManagedVPC
    Value: !GetAtt 
      - accessRoleCustomerManagedVPC
      - Arn
  DBManagedVPCIAMRoleARN:
    Description: ARN of the cross-account IAM role.
    Condition: CreateDBManagedVPC
    Value: !GetAtt 
      - accessRoleDBManagedVPC
      - Arn
  S3BucketName:
    Description: Name of the S3 root bucket.
    Value: !Ref assetsS3Bucket
  CustomerManagedKeyId:
    Description: ID of the customer managed key object.
    Condition: IsKMSKeyProvided
    Value: !GetAtt createCustomerManagedKey.CustomerManagedKeyId
  CredentialsId:
    Description: Credential ID.
    Value: !GetAtt createCredentials.CredentialsId
  ExternalId:
    Description: Databricks external ID.
    Value: !GetAtt createCredentials.ExternalId
  NetworkId:
    Description: Databricks network ID.
    Condition: CustomerManagedVPC
    Value: !GetAtt createNetworks.NetworkId 
  StorageConfigId:
    Description: Storage configuration ID.
    Value: !GetAtt createStorageConfiguration.StorageConfigId
  WorkspaceURL:
    Description: URL of the workspace.
    Value: !Join
      - ''
      - - 'https://'
        - !GetAtt createWorkspace.DeploymentName
        - '.cloud.databricks.com'
  WorkspaceStatus:
    Description: Status of the requested workspace.
    Value: !GetAtt createWorkspace.WorkspaceStatus
  WorkspaceStatusMessage:
    Description: Detailed status description of the requested workspace.
    Value: !GetAtt createWorkspace.WorkspaceStatusMsg
  PricingTier:
    Description: Pricing tier of the workspace. For more information, see https://databricks.com/product/aws-pricing.
    Value: !GetAtt createWorkspace.PricingTier
  ClusterPolicyID:
    Description: Unique identifier for the cluster policy.
    Value: !GetAtt createWorkspace.ClusterPolicyId

Parameters:
  AccountId:
    Description: "Account must use the E2 version of the platform. For more information, see https://docs.databricks.com/getting-started/overview.html#e2-architecture." 
    AllowedPattern: '^[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12}$'
    MinLength: '36'
    Type: String
    Default: aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee
  Username:
    Description: "Account email for authenticating the REST API. Note that this value is case sensitive."
    AllowedPattern: '^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+.[a-zA-Z0-9-.]+$'
    ConstraintDescription: Must be a valid email format.
    MinLength: '8'
    Type: String
  Password:
    Description: "Account password for authenticating the REST API. The minimum length is 8 alphanumeric characters."
    MinLength: '8'
    NoEcho: 'true'
    Type: String
  PricingTier:
    Description: "If you do not provide this, the API defaults to the highest pricing tier. For more information, see https://databricks.com/product/aws-pricing."
    AllowedValues:
       - STANDARD
       - PREMIUM 
       - ENTERPRISE
       - '' 
    Type: String
    Default: ''
  DeploymentName:
    Description: "Choose this value carefully. The deployment name defines part of the workspace subdomain (e.g., workspace-deployment-name.cloud.databricks.com). This value must be unique across all deployments in all AWS Regions. It cannot start or end with a hyphen. If your account has a deployment-name prefix, add the prefix followed by a hyphen. For more information, see https://docs.databricks.com/administration-guide/account-api/new-workspace.html#step-5-create-the-workspace."
    AllowedPattern: '^(([a-z0-9][a-z0-9-]*[a-z0-9])|([a-z0-9]))$'
    ConstraintDescription: You must enter a valid subdomain for the workspace.
    Type: String
  AWSRegion:
    Description: "AWS Region where the workspace is created. Note that customer managed keys to encrypt notebooks are not supported in the us-west-1 Region."
    MinLength: '9'
    AllowedValues:
       - ap-northeast-1
       - ap-south-1
       - ap-southeast-1
       - ap-southeast-2
       - ca-central-1
       - eu-central-1
       - eu-west-1
       - eu-west-2
       - us-east-1
       - us-east-2
       - us-west-1
       - us-west-2
    Type: String
  HIPAAparm:
    Description: 'Entering "Yes" creates a template for creating clusters in the HIPAA account.'
    AllowedValues:
       - 'Yes'
       - 'No'
    Default: 'No'
    Type: String
  TagValue:
    Description: "All new AWS objects get a tag with the key name. Enter a value to identify all new AWS objects that this template creates. For more information, see https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html."
    MinLength: '1'
    Type: String
    Default: databricks-quickstart-cloud-formation
  IAMRole: 
    Description: "Enter a unique cross-account IAM role name. For more information, see https://docs.aws.amazon.com/IAM/latest/APIReference/API_CreateRole.html."
    AllowedPattern: '[\w+=,@-]+'
    Type: String
    MinLength: '1'
    MaxLength: '64'
  BucketName:
    Description: "Name of your S3 root bucket. Enter only alphanumeric characters. For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html."
    AllowedPattern: '(?=^.{3,63}$)(?!xn--)([a-z0-9](?:[a-z0-9-]*)[a-z0-9])$'
    MinLength: '3'
    MaxLength: '63'
    Type: String
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
  VPCID:
    Description: "ID of your VPC in which to create the new workspace. Only enter a value if you use the customer managed VPC feature. The format is vpc-xxxxxxxxxxxxxxxx. If unspecified, Databricks creates a new workspace in a new VPC. For more information, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html."
    Type: String
    Default: '' 
  SecurityGroupIDs:
    Description: "Name of one or more VPC security groups. Only enter a value if you set VPCID. The format is sg-xxxxxxxxxxxxxxxxx. Use commas to separate multiple IDs. Databricks must have access to at least one security group but no more than five. You can reuse existing security groups. For more information, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html."
    Type: String
    Default: '' 
  SubnetIDs:
    Description: "Enter at least two private subnet IDs. Only enter a value if you set VPCID. Subnets cannot be shared with other workspaces or non-Databricks resources. Each subnet must be private, have outbound access, and a netmask between /17 and /25. The NAT gateway must have its own subnet that routes 0.0.0.0/0 traffic to an internet gateway. For more information, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html."
    Type: String
    Default: '' 
  KeyArn:
    Description: "AWS KMS key ARN to encrypt and decrypt workspace notebooks in the control plane. Only enter a value if you use the customer managed key for notebooks. For more information, see https://docs.databricks.com/security/keys/customer-managed-keys-notebook-aws.html."
    Type: String
    Default: ''
  KeyAlias:
    Description: "(Optional) AWS KMS key alias."
    Type: String
    Default: ''
  KeyUseCases:
    Description: "Configures customer managed encryption keys. Acceptable values are MANAGED_SERVICES, STORAGE, or BOTH. For more information, see https://docs.databricks.com/administration-guide/account-api/new-workspace.html#step-5-configure-customer-managed-keys-optional."
    Type: String 
  KeyReuseForClusterVolumes:
    Description: 'Only enter a value if the use case is STORAGE or BOTH. Acceptable values are "True" and "False."'
    Type: String
  QSS3BucketName:
    Description: "S3 bucket for Quick Start assets. Use this if you want to customize the Quick Start. The bucket name can include numbers, lowercase letters, uppercase letters, and hyphens, but it cannot start or end with a hyphen (-)."
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    Default: aws-quickstart
    Type: String
    MinLength: '3'
    MaxLength: '63'
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
  QSS3KeyPrefix:
    Description: "S3 key prefix to simulate a directory for your Quick Start assets. Use this if you want to customize the Quick Start. The prefix can include numbers, lowercase letters, uppercase letters, hyphens (-), and forward slashes (/). For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html."
    AllowedPattern: '^[0-9a-zA-Z-/]*$'
    Type: String
    Default: quickstart-databricks-unified-data-analytics-platform/
  

Conditions:
# Set condition when VPC ID is provided by the user
  CustomerManagedVPC: !Not [!Equals [!Ref VPCID, '']]
# Set condition when VPC ID is NOT provided by the user
  CreateDBManagedVPC: !Equals [!Ref VPCID, '']
# Set condition when AWS KMS key ID is provided by the user. 
  IsKMSKeyProvided: !Not [!Equals [!Ref KeyArn, '']]
# Test for STORAGE CMK use case
  IsClusterVolumeSet: !Equals [!Ref KeyReuseForClusterVolumes, 'True']

Rules:
# 1. Validate the selected Region from drop-down matches the Region from the Console
  RunningTemplateFromDifferentRegionThanDropDown:
    Assertions:
    - Assert: !Equals [!Ref AWSRegion, !Ref 'AWS::Region']
      AssertDescription: Region from the AWS Management Console must match the selected Region from the drop-down menu.

# 2. HIPAA supported regions, if HIPAA flaf is set
  SupportedHipaaRegions:
    RuleCondition: !Equals [!Ref HIPAAparm, 'Yes']
    Assertions:
    - Assert: !Contains [['us-east-1', 'us-east-2', 'ca-central-1'], !Ref AWSRegion]
      AssertDescription: Creates a workspace for only HIPAA tier accounts in the us-east-1, us-east-2, and ca-central-1 Regions.

# 3. Optional section. Ensure that the SubnetIds and SecurityGroupIds are provided, if the user provides a customer managed VPC ID
  CustomerManagedVPC:
    RuleCondition: !Not [!Equals [!Ref VPCID, '']]
    Assertions:
    - Assert: !Not [!Equals ['', !Ref SubnetIDs]]
      AssertDescription: SubnetIDs is required when VPCID is provided.
    - Assert: !Not [!Equals ['', !Ref SecurityGroupIDs]]
      AssertDescription: SecurityGroupIDs is required when VPCID is provided.

# 4. Optional Section. Ensure the KeyARN is provided when a use case is specified.
  KeyUseCases1:
    RuleCondition: !Not [!Equals [!Ref KeyArn, '']]
    Assertions:
    - Assert: !Contains [['MANAGED_SERVICES', 'STORAGE', 'BOTH'],!Ref KeyUseCases]
      AssertDescription: Acceptable values are MANAGED_SERVICES, STORAGE, or BOTH when you provide a role ARN.
    
  KeyUseCases2:
    RuleCondition: !Or
      - !Equals [!Ref KeyUseCases, 'STORAGE']
      - !Equals [!Ref KeyUseCases, 'BOTH']
    Assertions:
    - Assert: !Contains [['True', 'False'], !Ref KeyReuseForClusterVolumes]
      AssertDescription: 'Acceptable values are "True" and "False" when the use case is either STORAGE or BOTH.' 
 
  KeyUseCases3:
    RuleCondition: !Equals [!Ref KeyUseCases, 'MANAGED_SERVICES']
    Assertions: 
    - Assert: !Equals [!Ref KeyReuseForClusterVolumes, '']
      AssertDescription: Value must be null if MANAGED_SERVICES is specified.

# 5. Assertion rule to prevent changing the QuickStart Bucket name and Prefix parameter
# ***********************************************************************************************************************
# This rule must be COMMENTED if it is intended to clone the git repo to make modifications prior to promote the changes
# ***********************************************************************************************************************
  AWSQuickStartGitParametersSettings:
    Assertions:
    - Assert: !Equals ['aws-quickstart', !Ref QSS3BucketName]
      AssertDescription: 'QSS3BucketName must be aws-quickstart.'
    - Assert: !Equals ['quickstart-databricks-unified-data-analytics-platform/', !Ref QSS3KeyPrefix]
      AssertDescription: 'QSS3KeyPrefix must be quickstart-databricks-unified-data-analytics-platform/.'
        
Resources:
  # Cross-account access role for Databricks-created and managed VPC
  accessRoleDBManagedVPC:
    Type: 'AWS::IAM::Role'
    Metadata:
      cfn-lint:
        config:
          ignore_checks:
            - EIAMPolicyWildcardResource
            - EIAMAccountIDInPrincipal
          ignore_reasons:
            EIAMPolicyWildcardResource: "Need to manage databricks workspaces"
            EIAMAccountIDInPrincipal: "Hardcoded account ID needed for configuration: https://docs.databricks.com/administration-guide/account-settings/aws-accounts.html#step-2-create-a-cross-account-role-and-an-access-policy"
    Condition: CreateDBManagedVPC
    Properties:
      RoleName: !Ref IAMRole
      AssumeRolePolicyDocument:
        Statement:
          - Action: 'sts:AssumeRole'
            Condition:
              StringEquals: 
                'sts:ExternalId': !Sub '${AccountId}'
            Effect: Allow
            Principal:
              AWS: !Join 
                - ''
                - - 'arn:aws:iam::'
                  - '414351767826'
                  - ':root'
            Sid: ''
        Version: 2012-10-17
      Path: /
      Policies:
        - PolicyDocument:
            Statement:
              - Sid: Stmt1403287045000
                Effect: Allow
                Action:
                  - 'ec2:AllocateAddress'
                  - 'ec2:AssociateDhcpOptions'
                  - 'ec2:AssociateIamInstanceProfile'
                  - 'ec2:AssociateRouteTable'
                  - 'ec2:AttachInternetGateway'
                  - 'ec2:AttachVolume'
                  - 'ec2:AuthorizeSecurityGroupEgress'
                  - 'ec2:AuthorizeSecurityGroupIngress'
                  - 'ec2:CancelSpotInstanceRequests'
                  - 'ec2:CreateDhcpOptions'
                  - 'ec2:CreateInternetGateway'
                  - 'ec2:CreateKeyPair'
                  - 'ec2:CreateNatGateway'
                  - 'ec2:CreatePlacementGroup'
                  - 'ec2:CreateRoute'
                  - 'ec2:CreateRouteTable'
                  - 'ec2:CreateSecurityGroup'
                  - 'ec2:CreateSubnet'
                  - 'ec2:CreateTags'
                  - 'ec2:CreateVolume'
                  - 'ec2:CreateVpc'
                  - 'ec2:CreateVpcEndpoint'
                  - 'ec2:DeleteDhcpOptions'
                  - 'ec2:DeleteInternetGateway'
                  - 'ec2:DeleteKeyPair'
                  - 'ec2:DeleteNatGateway'
                  - 'ec2:DeletePlacementGroup'
                  - 'ec2:DeleteRoute'
                  - 'ec2:DeleteRouteTable'
                  - 'ec2:DeleteSecurityGroup'
                  - 'ec2:DeleteSubnet'
                  - 'ec2:DeleteTags'
                  - 'ec2:DeleteVolume'
                  - 'ec2:DeleteVpc'
                  - 'ec2:DeleteVpcEndpoints'
                  - 'ec2:DescribeAvailabilityZones'
                  - 'ec2:DescribeIamInstanceProfileAssociations'
                  - 'ec2:DescribeInstanceStatus'
                  - 'ec2:DescribeInstances'
                  - 'ec2:DescribeInternetGateways'
                  - 'ec2:DescribeNatGateways'
                  - 'ec2:DescribePlacementGroups'
                  - 'ec2:DescribePrefixLists'
                  - 'ec2:DescribeReservedInstancesOfferings'
                  - 'ec2:DescribeRouteTables'
                  - 'ec2:DescribeSecurityGroups'
                  - 'ec2:DescribeSpotInstanceRequests'
                  - 'ec2:DescribeSpotPriceHistory'
                  - 'ec2:DescribeSubnets'
                  - 'ec2:DescribeVolumes'
                  - 'ec2:DescribeVpcs'
                  - 'ec2:DetachInternetGateway'
                  - 'ec2:DisassociateIamInstanceProfile'
                  - 'ec2:DisassociateRouteTable'
                  - 'ec2:ModifyVpcAttribute'
                  - 'ec2:ReleaseAddress'
                  - 'ec2:ReplaceIamInstanceProfileAssociation'
                  - 'ec2:ReplaceRoute'
                  - 'ec2:RequestSpotInstances'
                  - 'ec2:RevokeSecurityGroupEgress'
                  - 'ec2:RevokeSecurityGroupIngress'
                  - 'ec2:RunInstances'
                  - 'ec2:TerminateInstances'
                Resource:
                  - '*'
              - Effect: Allow
                Action:
                  - 'iam:CreateServiceLinkedRole'
                  - 'iam:PutRolePolicy'
                Resource:
                  - !Sub 'arn:${AWS::Partition}:iam::*:role/aws-service-role/spot.amazonaws.com/AWSServiceRoleForEC2Spot'
                Condition:
                  StringLike:
                    'iam:AWSServiceName': spot.amazonaws.com
            Version: 2012-10-17
          PolicyName: databricks-cross-account-iam-role-policy
      Tags:
        -
          Key: Name
          Value: !Sub '${TagValue}-IAMRole'
  
  # Cross-account access role for customer managed VPC
  accessRoleCustomerManagedVPC:
    Type: 'AWS::IAM::Role'
    Metadata:
      cfn-lint:
        config:
          ignore_checks:
            - EIAMPolicyWildcardResource
            - EIAMAccountIDInPrincipal
          ignore_reasons:
            EIAMPolicyWildcardResource: "Need to manage databricks workspaces"
            EIAMAccountIDInPrincipal: "Hardcoded account ID needed for configuration: https://docs.databricks.com/administration-guide/account-settings/aws-accounts.html#step-2-create-a-cross-account-role-and-an-access-policy"
    Condition: CustomerManagedVPC
    Properties:
      RoleName: !Ref IAMRole
      AssumeRolePolicyDocument:
        Statement:
          - Action: 'sts:AssumeRole'
            Condition:
               StringEquals: 
                'sts:ExternalId': !Sub '${AccountId}'
            Effect: Allow
            Principal:
              AWS: !Join 
                - ''
                - - 'arn:aws:iam::'
                  - '414351767826'
                  - ':root'
            Sid: ''
        Version: 2012-10-17
      Path: /
      Policies:
        - PolicyDocument:
            Statement:
              - Sid: NonResourceBasedPermissions
                Effect: Allow
                Action:
                  - 'ec2:CancelSpotInstanceRequests'
                  - 'ec2:DescribeAvailabilityZones'
                  - 'ec2:DescribeIamInstanceProfileAssociations'
                  - 'ec2:DescribeInstanceStatus'
                  - 'ec2:DescribeInstances'
                  - 'ec2:DescribeInternetGateways'
                  - 'ec2:DescribeNatGateways'
                  - 'ec2:DescribeNetworkAcls'
                  - 'ec2:DescribePlacementGroups'
                  - 'ec2:DescribePrefixLists'
                  - 'ec2:DescribeReservedInstancesOfferings'
                  - 'ec2:DescribeRouteTables'
                  - 'ec2:DescribeSecurityGroups'
                  - 'ec2:DescribeSpotInstanceRequests'
                  - 'ec2:DescribeSpotPriceHistory'
                  - 'ec2:DescribeSubnets'
                  - 'ec2:DescribeVolumes'
                  - 'ec2:DescribeVpcAttribute'
                  - 'ec2:DescribeVpcs'
                  - 'ec2:CreatePlacementGroup'
                  - 'ec2:DeletePlacementGroup'
                  - 'ec2:CreateKeyPair'
                  - 'ec2:DeleteKeyPair'
                  - 'ec2:CreateTags'
                  - 'ec2:DeleteTags'
                  - 'ec2:RequestSpotInstances'
                Resource:
                  - '*'
              - Sid: InstancePoolsSupport
                Effect: Allow
                Action:
                  - 'ec2:AssociateIamInstanceProfile'
                  - 'ec2:DisassociateIamInstanceProfile'
                  - 'ec2:ReplaceIamInstanceProfileAssociation'
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:instance/* 
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'
              - Sid: AllowEc2RunInstancePerTag
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:volume/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:instance/*
                Condition:
                  StringEquals:
                    'aws:RequestTag/Vendor': 'Databricks' 
              - Sid: AllowEc2RunInstanceImagePerTag
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:image/*
                Condition:
                  StringEquals:
                    'aws:ResourceTag/Vendor': 'Databricks'
              - Sid: AllowEc2RunInstancePerVPCid
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:network-interface/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:subnet/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:security-group/*
                Condition:
                  StringEquals:
                    'ec2:vpc' : !Sub 'arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:vpc/${VPCID}'
              - Sid: AllowEc2RunInstanceOtherResources
                Effect: Allow
                Action:
                  - 'ec2:RunInstances'
                NotResource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:image/* 
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:network-interface/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:subnet/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:security-group/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:volume/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:instance/* 
              - Sid: EC2TerminateInstancesTag
                Effect: Allow
                Action:
                  - 'ec2:TerminateInstances'
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:instance/*
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks' 
              - Sid: EC2AttachDetachVolumeTag
                Effect: Allow
                Action:
                  - 'ec2:AttachVolume'
                  - 'ec2:DetachVolume'
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:instance/* 
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:volume/*
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'
              - Sid: EC2CreateVolumeByTag
                Effect: Allow
                Action:
                  - 'ec2:CreateVolume'
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:volume/* 
                Condition:
                  StringEquals:
                    'aws:RequestTag/Vendor': 'Databricks' 
              - Sid: EC2DeleteVolumeByTag
                Effect: Allow
                Action:
                  - 'ec2:DeleteVolume'
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWSRegion}:${AWS::AccountId}:volume/* 
                Condition:
                  StringEquals:
                    'ec2:ResourceTag/Vendor': 'Databricks'
              - Effect: Allow
                Action:
                  - 'iam:CreateServiceLinkedRole'
                  - 'iam:PutRolePolicy'
                Resource: 
                  - !Sub arn:${AWS::Partition}:iam::*:role/aws-service-role/spot.amazonaws.com/AWSServiceRoleForEC2Spot
                Condition:
                  StringLike:
                    'iam:AWSServiceName': spot.amazonaws.com
            Version: 2012-10-17
          PolicyName: databricks-cross-account-iam-role-policy
      Tags:
        -
          Key: Name
          Value: !Sub '${TagValue}-IAMRole'

  # S3 root bucket requirements
  assetsS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref BucketName
      PublicAccessBlockConfiguration:
        BlockPublicAcls       : true
        BlockPublicPolicy     : true
        IgnorePublicAcls      : true
        RestrictPublicBuckets : true
  bucketPolicy:
    Type: 'AWS::S3::BucketPolicy'
    Metadata:
      cfn-lint:
        config:
          ignore_checks:
            - EIAMAccountIDInPrincipal
          ignore_reasons:
            EIAMAccountIDInPrincipal: "Hardcoded account ID needed for configuration: https://docs.databricks.com/administration-guide/account-settings/aws-accounts.html#step-2-create-a-cross-account-role-and-an-access-policy"
    Properties: 
      PolicyDocument:
        Id: MyPolicy
        Version: 2012-10-17
        Statement:
          - Sid: Grant Databricks Access
            Effect: Allow
            Principal:
              AWS: arn:aws:iam::414351767826:root
            Action:
              - 's3:GetObject'
              - 's3:GetObjectVersion'
              - 's3:PutObject'
              - 's3:DeleteObject'
              - 's3:ListBucket'
              - 's3:GetBucketLocation'
            Resource:
              - !Sub 'arn:${AWS::Partition}:s3:::${assetsS3Bucket}/*'
              - !Sub 'arn:${AWS::Partition}:s3:::${assetsS3Bucket}'
      Bucket: !Ref assetsS3Bucket 

  # Databricks API for configuring notebook encryption with a customer managed AWS KMS, if provided
  createCustomerManagedKey:
    Condition: IsKMSKeyProvided
    DependsOn: updateCustomManagedKeys
    Type: Custom::CreateCustomerManagedKey
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_CUSTOMER_MANAGED_KEY'
      accountId: !Ref AccountId
      key_arn: !Ref KeyArn
      key_alias: !Ref KeyAlias
      use_cases: !Ref KeyUseCases
      reuse_key_for_cluster_volumes: !Ref KeyReuseForClusterVolumes
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'
      user_agent: 'databricks-CloudFormation-provider'

  # Databricks API for workspace credentials
  createCredentials:
    Type: Custom::CreateCredentials
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_CREDENTIALS'
      accountId: !Ref AccountId
      credentials_name: !Join
        - '-'
        - - !Ref DeploymentName
          - 'credentials'
      role_arn: !If [CustomerManagedVPC, !GetAtt 'accessRoleCustomerManagedVPC.Arn', !GetAtt 'accessRoleDBManagedVPC.Arn']
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'
      user_agent: 'databricks-CloudFormation-provider'

  # Databricks API for workspace storage configuration
  createStorageConfiguration:
    Type: Custom::CreateStorageConfigurations
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_STORAGE_CONFIGURATIONS'
      accountId: !Ref AccountId
      storage_config_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'storage'
      s3bucket_name: !Ref assetsS3Bucket
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'
      user_agent: 'databricks-CloudFormation-provider'

  # Databricks API for customer managed VPC
  createNetworks:
    DependsOn: createStorageConfiguration
    Condition: CustomerManagedVPC
    Type: Custom::createNetworks
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_NETWORKS'
      accountId: !Ref AccountId
      network_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'network'
      vpc_id: !Ref VPCID
      subnet_ids: !Ref SubnetIDs
      security_group_ids: !Ref SecurityGroupIDs
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'
      user_agent: 'databricks-CloudFormation-provider'

  # Databricks API for workspace creation
  createWorkspace:
    Type: Custom::CreateWorkspace
    Properties:
      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
      action: 'CREATE_WORKSPACES'
      accountId: !Ref AccountId
      workspace_name: !Join
        - '-'
        - - !Ref 'DeploymentName'
          - 'workspace'
      deployment_name: !Ref 'DeploymentName'
      aws_region: !Ref AWSRegion
      credentials_id: !GetAtt createCredentials.CredentialsId
      storage_config_id: !GetAtt createStorageConfiguration.StorageConfigId
      encodedbase64: 
        Fn::Base64: !Join
          - ':'
          - - !Ref 'Username'
            - !Ref 'Password'
      network_id: !If [CustomerManagedVPC, !GetAtt 'createNetworks.NetworkId', '']
      customer_managed_key_id: !If [IsKMSKeyProvided, !GetAtt 'createCustomerManagedKey.CustomerManagedKeyId', '']
      pricing_tier: !Ref PricingTier
      hipaa_parm: !Ref HIPAAparm
      customer_name: ''
      authoritative_user_email: ''
      authoritative_user_full_name: ''
      user_agent: 'databricks-CloudFormation-provider'
  
  # Customer managed VPC - Create databricks-cross-account-iam-role-policy-sg policy 
  updateIAMSecurityGroupIds:
    Condition: CustomerManagedVPC 
    DependsOn: updateIAMRoleFunction
    Type: Custom::UpdateRoleAssumePolicy
    Properties:
      ServiceToken: !GetAtt 'updateIAMRoleFunction.Arn'
      role_name: !Ref IAMRole
      aws_region: !Ref AWSRegion
      accountId: !Ref AWS::AccountId
      security_group_ids: !Ref SecurityGroupIDs
      VPCID: !Ref VPCID

  # Customer managed Keys - Update Storage policy for S3 and EBS volumes 
  updateCustomManagedKeys:
    Condition: IsKMSKeyProvided
    DependsOn: updateKMSkeysFunction
    Type: Custom::updateCustomManagedKeys
    Properties:
      ServiceToken: !GetAtt 'updateKMSkeysFunction.Arn'
      key_id: !Ref KeyArn
      arn_credentials: !If [CreateDBManagedVPC, !GetAtt 'accessRoleDBManagedVPC.Arn', !GetAtt 'accessRoleCustomerManagedVPC.Arn']
      use_cases: !Ref KeyUseCases
      reuse_key_for_cluster_volumes: !Ref KeyReuseForClusterVolumes

  # Databricks main Lambda for all E2 objects and workspace creation
  databricksApiFunction:
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: Databricks account API.
      Handler: rest_client.handler
      Runtime: python3.8
      Role: !GetAtt 'functionRole.Arn'
      Timeout: 900
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/lambda.zip' 
  
  # Databricks lambda for updating the Security Group Ids 
  updateIAMRoleFunction:
    Condition: CustomerManagedVPC
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: Update IAM role policy document using the list of security group IDs.
      Handler: update_custommanagedvpc_iam_role.handler
      Runtime: python3.8
      Role: !GetAtt 'functionRole.Arn'
      Timeout: 60
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/lambda.zip'

  # Databricks CMK lambda
  updateKMSkeysFunction:
    Condition: IsKMSKeyProvided
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: UUpdate CMK policy document for storage.
      Handler: update_custommanaged_cmk_policy.handler
      Runtime: python3.8
      Role: !GetAtt 'functionRole.Arn'
      Timeout: 60
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/lambda.zip'

  # IAM Role for lambda function execution
  functionRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn-lint:
        config:
          ignore_checks:
            - EIAMPolicyWildcardResource
          ignore_reasons:
            EIAMPolicyWildcardResource: "Need to manage databricks workspaces"
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole 
      Policies:
        - PolicyName: kmsUpdateRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: 
                  - 'kms:GetKeyPolicy'
                  - 'kms:PutKeyPolicy'
                Resource: '*' 
        - PolicyName: iamUpdateRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: 
                  - 'iam:PutRolePolicy'
                Resource: '*'
      Tags:
        -
          Key: Name
          Value: !Sub '${TagValue}-IAMRole'

  # Resources to stage lambda.zip file
  LambdaZipsBucket:
    Type: AWS::S3::Bucket
  CopyZips:
    Type: Custom::CopyZips
    Properties:
      ServiceToken: !GetAtt 'CopyZipsFunction.Arn'
      DestBucket: !Ref 'LambdaZipsBucket'
      SourceBucket: !Ref 'QSS3BucketName'
      Prefix: !Ref 'QSS3KeyPrefix'
      Objects:
        - functions/packages/lambda.zip
  CopyZipsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - !Sub 'arn:${AWS::Partition}:s3:::${QSS3BucketName}/${QSS3KeyPrefix}*'
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:DeleteObject
                Resource:
                  - !Sub 'arn:${AWS::Partition}:s3:::${LambdaZipsBucket}/${QSS3KeyPrefix}*' 
      Tags:
        -
          Key: Name
          Value: !Sub '${TagValue}-IAMRole'


  CopyZipsFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Copies objects from an S3 bucket to another destination.
      Handler: index.handler
      Runtime: python3.8
      Role: !GetAtt 'CopyZipsRole.Arn'
      Timeout: 240
      Code:
        ZipFile: |
          import json
          import logging
          import threading
          import boto3
          import cfnresponse
          def copy_objects(source_bucket, dest_bucket, prefix, objects):
              s3 = boto3.client('s3')
              for o in objects:
                  key = prefix + o
                  copy_source = {
                      'Bucket': source_bucket,
                      'Key': key
                  }
                  print('copy_source: %s' % copy_source)
                  print('dest_bucket = %s'%dest_bucket)
                  print('key = %s' %key)
                  s3.copy_object(CopySource=copy_source, Bucket=dest_bucket,
                        Key=key)
          def delete_objects(bucket, prefix, objects):
              s3 = boto3.client('s3')
              objects = {'Objects': [{'Key': prefix + o} for o in objects]}
              s3.delete_objects(Bucket=bucket, Delete=objects)
          def timeout(event, context):
              logging.error('Execution is about to time out, sending failure response to CloudFormation')
              cfnresponse.send(event, context, cfnresponse.FAILED, {}, None)
          def handler(event, context):
              # make sure we send a failure to CloudFormation if the function
              # is going to timeout
              timer = threading.Timer((context.get_remaining_time_in_millis()
                        / 1000.00) - 0.5, timeout, args=[event, context])
              timer.start()
              print('Received event: %s' % json.dumps(event))
              status = cfnresponse.SUCCESS
              try:
                  source_bucket = event['ResourceProperties']['SourceBucket']
                  dest_bucket = event['ResourceProperties']['DestBucket']
                  prefix = event['ResourceProperties']['Prefix']
                  objects = event['ResourceProperties']['Objects']
                  if event['RequestType'] == 'Delete':
                      delete_objects(dest_bucket, prefix, objects)
                  else:
                      copy_objects(source_bucket, dest_bucket, prefix, objects)
              except Exception as e:
                  logging.error('Exception: %s' % e, exc_info=True)
                  status = cfnresponse.FAILED
              finally:
                  timer.cancel()
                  cfnresponse.send(event, context, status, {}, None)
                  